{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample,seed,shuffle\n",
    "np.random.seed(42)\n",
    "random_state = np.random.RandomState(42)\n",
    "seed(a=42)\n",
    "\n",
    "files = glob.glob(\"/Users/javie/OneDrive/Documentos/CIMAT/Sem 3/Preprocesamiento/Tarea 2/csv/*.csv\")\n",
    "Data_frames=[]\n",
    "for file in files:    \n",
    "    Data_frames.append(pd.read_csv(file))\n",
    "Dfs5  = list( Data_frames[i] for i in [3,7,11])\n",
    "Dfs10 = list( Data_frames[i] for i in [0,4,8])\n",
    "Dfs15 = list( Data_frames[i] for i in [1,5,9])\n",
    "Dfs20 = list( Data_frames[i] for i in [2,6,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, sum as sumnp\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class NoiseHandling(BaseEstimator):\n",
    "    def __init__(self, method = 'ENN', n_neighbors = 1, n_splits = 5, \n",
    "                 filter_type = 'majority', random_state = None):\n",
    "        self.method = method\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_splits = n_splits\n",
    "        self.filter_type = filter_type\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __filtering_rule(self, y_pred, y):\n",
    "        if self.filter_type == 'majority':\n",
    "            y_pred_mode = mode(y_pred, axis = 1)[0].ravel()\n",
    "            return y_pred_mode == y\n",
    "        elif self.filter_type == 'consensus':\n",
    "            y_pred_bool = y_pred == y[:, None]\n",
    "            return sumnp(y_pred_bool, axis = 1) > 0\n",
    "        else:\n",
    "            raise ValueError('Undefined rule')\n",
    "\n",
    "    #Iterative edited-K Nearest Centroid Neighborhood\n",
    "    def __iekncn_fit(self, X, y):\n",
    "        f = True\n",
    "        y=pd.DataFrame(y)\n",
    "        y_aux=y\n",
    "\n",
    "        while f == True:\n",
    "            clf = NearestCentroid()\n",
    "            clf.fit(X, y_aux.values.ravel())\n",
    "            labels = clf.predict(X)\n",
    "            y_pred =labels.ravel()\n",
    "\n",
    "            if (labels==y_aux.values.ravel()).sum()!=len(y_aux):\n",
    "                X=X[labels==y_aux.values.ravel()]\n",
    "                y_aux=y_aux[labels==y_aux.values.ravel()]\n",
    "            else:\n",
    "                f=False\n",
    "        \n",
    "        indexes = np.arange(len(y))\n",
    "        j = 0\n",
    "        Filter=[]\n",
    "        for i in range(len(indexes)):\n",
    "            if indexes[i]==y_aux.index[j]:\n",
    "                Filter.append(True)\n",
    "                j=j+1\n",
    "            else:\n",
    "                Filter.append(False)\n",
    "        self.filter_ = Filter\n",
    "        return self\n",
    "            \n",
    "            \n",
    "    #Complementary Neural Network\n",
    "    def __cmtnn_fit(self,X,y):  \n",
    "        \n",
    "        y_comp=y\n",
    "        shuffle(y_comp)\n",
    "        mt = MLPClassifier(random_state=1, max_iter=500).fit(X,y)\n",
    "        mc = MLPClassifier(random_state=1, max_iter=500).fit(X,y_comp)\n",
    "        y_t = mt.predict(X)\n",
    "        y_c = mc.predict(X)        \n",
    "        \n",
    "        self.filter_ = (y!=y_t)&(y!=y_c)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    #Decremental Reduction Optimization Procedure\n",
    "    def __drop_fit(self, X, y):\n",
    "        S = X\n",
    "        nn_search = NearestNeighbors(n_neighbors = 5 + 1)\n",
    "        nn_search.fit(S)\n",
    "        neigh_ind = nn_search.kneighbors(S, return_distance = False)\n",
    "        Filter=[]\n",
    "\n",
    "        for i in range(np.shape(neigh_ind)[0]):\n",
    "            #associates.append(X[neigh_ind[i,1:]])\n",
    "            neigh = KNeighborsClassifier(n_neighbors=5+1)\n",
    "            neigh.fit(X, y)\n",
    "            ni =  (neigh.predict(X[neigh_ind[i,:]])==y[neigh_ind[i,:]]).sum()\n",
    "            ne =  (neigh.predict(X[neigh_ind[i,1:]])==y[neigh_ind[i,1:]]).sum()\n",
    "            Filter.append(ni<=ne)\n",
    "        print(np.sum(Filter))\n",
    "        self.filter_ = Filter\n",
    "        return self\n",
    "    \n",
    "    # Cross Validates Commites Filter \n",
    "    def __cvcf_fit(self,X,y):\n",
    "        skf = StratifiedKFold(n_splits = self.n_splits, shuffle = True,\n",
    "                              random_state = self.random_state)\n",
    "        predictions = zeros((X.shape[0], 3))\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            \n",
    "            model = DecisionTreeClassifier(random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X)\n",
    "            \n",
    "        self.filter_ = predictions == y\n",
    "        return self   \n",
    "    \n",
    "    #Edited Nearest Neighbor\n",
    "    def __enn_fit(self, X, y):\n",
    "        nn_search = NearestNeighbors(n_neighbors = self.n_neighbors + 1)\n",
    "        nn_search.fit(X)\n",
    "        neigh_ind = nn_search.kneighbors(X, return_distance = False)[:, 1:]\n",
    "        labels = y[neigh_ind]\n",
    "        y_pred = mode(labels, axis = 1)[0].ravel()\n",
    "        self.filter_ = y == y_pred\n",
    "        return self\n",
    "    \n",
    "    #Ensemble Filter\n",
    "    def __ef_fit(self, X, y):\n",
    "        skf = StratifiedKFold(n_splits = self.n_splits, shuffle = True,\n",
    "                              random_state = self.random_state)\n",
    "        predictions = zeros((X.shape[0], 3))\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            \n",
    "            learning_algorithms = [DecisionTreeClassifier(), \\\n",
    "                                  KNeighborsClassifier(), \\\n",
    "                                  LogisticRegression()]\n",
    "            for index, model in enumerate(learning_algorithms):\n",
    "                model.fit(X_train, y_train)\n",
    "                predictions[test_idx, index] = model.predict(X_test)\n",
    "                \n",
    "        self.filter_ = self.__filtering_rule(predictions, y)\n",
    "        return self \n",
    "    \n",
    "    def __filter_resample(self, X, y):\n",
    "        return X[self.filter_], y[self.filter_]\n",
    "            \n",
    "    def __resample(self, X, y):\n",
    "        X = check_array(X)\n",
    "        \n",
    "        if (self.method == 'ENN') or (self.method == 'EF') or (self.method == 'IEKNCN') or (self.method == 'DROP') or (self.method == 'CMTNN') or (self.method == 'CVCF'):\n",
    "            return self.__filter_resample(X, y)\n",
    "        else:\n",
    "            raise ValueError('Undefined method')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        if self.method == 'ENN':\n",
    "            return self.__enn_fit(X, y)\n",
    "        elif self.method == 'EF':\n",
    "            return self.__ef_fit(X, y)\n",
    "        elif self.method == 'IEKNCN':\n",
    "            return self.__iekncn_fit(X, y)\n",
    "        elif self.method == 'DROP':\n",
    "            return self.__drop_fit(X, y)        \n",
    "        elif self.method == 'CMTNN':\n",
    "            return self.__cmtnn_fit(X, y)\n",
    "        elif self.method == 'CVCF':\n",
    "            return self.__cvcf_fit(X, y)\n",
    "        else:\n",
    "            raise ValueError('Undefined method')\n",
    "            \n",
    "    def fit_resample(self, X, y):\n",
    "        return self.fit(X, y).__resample(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116  34]\n",
      " [ 54  66]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "AquÃ­ comienza la parte del script para prueba... Eliminar esto al no ser parte\n",
    "de la clase principal\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from imblearn.pipeline  import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dataset = load_iris()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "df = Dfs20[0]\n",
    "X = df.drop('Class', 1).to_numpy()\n",
    "y = df['Class']\n",
    "\n",
    "model = Pipeline([('standardize', StandardScaler()),\n",
    "                  ('noise_handler', \n",
    "                   NoiseHandling(method = 'CVCF', filter_type = 'consensus',\n",
    "                                 n_neighbors = 1)),\n",
    "                  ('classifier', KNeighborsClassifier())])\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = Dfs20[0]\n",
    "X = df.drop('Class', 1).to_numpy()\n",
    "y = df['Class']\n",
    "S = X\n",
    "\n",
    "nn_search = NearestNeighbors(n_neighbors = 5 + 1)\n",
    "nn_search.fit(S)\n",
    "neigh_ind = nn_search.kneighbors(S, return_distance = False)\n",
    "Filter=[]\n",
    "\n",
    "for i in range(np.shape(neigh_ind)[0]):\n",
    "    #associates.append(X[neigh_ind[i,1:]])\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5+1)\n",
    "    neigh.fit(X, y)\n",
    "    ni =  (neigh.predict(X[neigh_ind[i,:]])==y[neigh_ind[i,:]]).sum()\n",
    "    ne =  (neigh.predict(X[neigh_ind[i,1:]])==y[neigh_ind[i,1:]]).sum()\n",
    "    Filter.append(ni<=ne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block of code to implement drop \n",
    "\n",
    "associates=[]\n",
    "for i in range(np.shape(neigh_ind)[0]):\n",
    "    associates.append(X[neigh_ind[i,1:]])\n",
    "    treshold=2*(y[neigh_ind[i,1:]]==y[i]).sum() < len(y) \n",
    "    #print(treshold)\n",
    "    if treshold == False:\n",
    "        S = np.delete(S, i, 0)\n",
    "        #print(neigh_ind)\n",
    "        nn_search = NearestNeighbors(n_neighbors = 5 + 1)\n",
    "        nn_search.fit(S)\n",
    "        neigh_ind = nn_search.kneighbors(S, return_distance = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   2,   4,   5,   6,   7,   9,  10,  11,  13,\n",
       "            ...\n",
       "            249, 250, 251, 253, 255, 258, 265, 267, 268, 269],\n",
       "           dtype='int64', length=132)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Dfs20[0]\n",
    "X = df.drop('Class', 1).to_numpy()\n",
    "y = df['Class']\n",
    "\n",
    "f = True\n",
    "y_aux=y\n",
    "X_aux=X\n",
    "while f == True:\n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(X_aux, y_aux)\n",
    "    labels = clf.predict(X_aux) \n",
    "    y_pred =labels.ravel()\n",
    "            \n",
    "    if (labels==y_aux).sum()!=len(y_aux):\n",
    "        X_aux=X_aux[labels==y_aux]\n",
    "        y_aux=y_aux[labels==y_aux]\n",
    "    else:\n",
    "        f=False\n",
    "y_aux.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.arange(len(y))\n",
    "j = 0\n",
    "Filter=[]\n",
    "for i in range(len(indexes)):\n",
    "    if indexes[i]==y_aux.index[j]:\n",
    "        Filter.append(True)\n",
    "        j=j+1\n",
    "    else:\n",
    "        Filter.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
