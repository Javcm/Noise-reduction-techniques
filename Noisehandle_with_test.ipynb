{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample,seed,shuffle\n",
    "np.random.seed(42)\n",
    "random_state = np.random.RandomState(42)\n",
    "seed(a=42)\n",
    "\n",
    "files = glob.glob(\"/Users/javie/OneDrive/Documentos/CIMAT/Sem 3/Preprocesamiento/Tarea 2/csv/*.csv\")\n",
    "Data_frames=[]\n",
    "for file in files:    \n",
    "    Data_frames.append(pd.read_csv(file))\n",
    "Dfs5  = list( Data_frames[i] for i in [3,7,11])\n",
    "Dfs10 = list( Data_frames[i] for i in [0,4,8])\n",
    "Dfs15 = list( Data_frames[i] for i in [1,5,9])\n",
    "Dfs20 = list( Data_frames[i] for i in [2,6,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, sum as sumnp\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from imblearn.pipeline  import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as ss\n",
    "\n",
    "class NoiseHandling(BaseEstimator):\n",
    "    def __init__(self, method = 'ENN', n_neighbors = 1, n_splits = 5, \n",
    "                 filter_type = 'majority', random_state = None):\n",
    "        self.method = method\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_splits = n_splits\n",
    "        self.filter_type = filter_type\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __filtering_rule(self, y_pred, y):\n",
    "        if self.filter_type == 'majority':\n",
    "            y_pred_mode = mode(y_pred, axis = 1)[0].ravel()\n",
    "            return y_pred_mode == y\n",
    "        elif self.filter_type == 'consensus':\n",
    "            y_pred_bool = y_pred == y[:, None]\n",
    "            return sumnp(y_pred_bool, axis = 1) > 0\n",
    "        else:\n",
    "            raise ValueError('Undefined rule')\n",
    "\n",
    "    #Iterative edited-K Nearest Centroid Neighborhood\n",
    "    def __iekncn_fit(self, X, y):\n",
    "        f = True\n",
    "        y=pd.DataFrame(y)\n",
    "        y_aux=y\n",
    "\n",
    "        while f == True:\n",
    "            clf = NearestCentroid()\n",
    "            clf.fit(X, y_aux.values.ravel())\n",
    "            labels = clf.predict(X)\n",
    "            y_pred =labels.ravel()\n",
    "\n",
    "            if (labels==y_aux.values.ravel()).sum()!=len(y_aux):\n",
    "                X=X[labels==y_aux.values.ravel()]\n",
    "                y_aux=y_aux[labels==y_aux.values.ravel()]\n",
    "            else:\n",
    "                f=False\n",
    "        indexes = np.arange(len(y))\n",
    "        j = 0\n",
    "        Filter=[]\n",
    "\n",
    "        for i in range(len(indexes)):\n",
    "            if indexes[i]==y.index[j]:\n",
    "                Filter.append(True)\n",
    "                j=j+1\n",
    "            else:\n",
    "                Filter.append(False)\n",
    "        self.filter_ = Filter\n",
    "        return self\n",
    "            \n",
    "            \n",
    "    #Complementary Neural Network\n",
    "    def __cmtnn_fit(self,X,y):  \n",
    "        \n",
    "        y_comp=y\n",
    "        shuffle(y_comp)\n",
    "        mt = MLPClassifier(random_state=1, max_iter=500).fit(X,y)\n",
    "        mc = MLPClassifier(random_state=1, max_iter=500).fit(X,y_comp)\n",
    "        y_t = mt.predict(X)\n",
    "        y_c = mc.predict(X)        \n",
    "        self.filter_ = (y!=y_t)&(y!=y_c)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    #Decremental Reduction Optimization Procedure\n",
    "    def __drop_fit(self, X, y):\n",
    "        S = X\n",
    "        nn_search = NearestNeighbors(n_neighbors = 5 + 1)\n",
    "        nn_search.fit(S)\n",
    "        neigh_ind = nn_search.kneighbors(S, return_distance = False)\n",
    "        Filter=[]\n",
    "\n",
    "        for i in range(np.shape(neigh_ind)[0]):\n",
    "            #associates.append(X[neigh_ind[i,1:]])\n",
    "            neigh = KNeighborsClassifier(n_neighbors=5+1)\n",
    "            neigh.fit(X, y)\n",
    "            ni =  (neigh.predict(X[neigh_ind[i,:]])==y[neigh_ind[i,:]]).sum()\n",
    "            ne =  (neigh.predict(X[neigh_ind[i,1:]])==y[neigh_ind[i,1:]]).sum()\n",
    "            Filter.append(ni<=ne)\n",
    "        self.filter_ = list(map(operator.not_, Filter))\n",
    "        return self\n",
    "    \n",
    "    # Cross Validates Commites Filter \n",
    "    def __cvcf_fit(self,X,y):\n",
    "        skf = StratifiedKFold(n_splits = self.n_splits, shuffle = True,\n",
    "                              random_state = self.random_state)\n",
    "        predictions = zeros((X.shape[0], 3))\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            \n",
    "            model = DecisionTreeClassifier(random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X)\n",
    "            \n",
    "        self.filter_ = predictions == y\n",
    "        return self   \n",
    "    \n",
    "    #Edited Nearest Neighbor\n",
    "    def __enn_fit(self, X, y):\n",
    "        nn_search = NearestNeighbors(n_neighbors = self.n_neighbors + 1)\n",
    "        nn_search.fit(X)\n",
    "        neigh_ind = nn_search.kneighbors(X, return_distance = False)[:, 1:]\n",
    "        labels = y[neigh_ind]\n",
    "        y_pred = mode(labels, axis = 1)[0].ravel()\n",
    "        self.filter_ = y == y_pred\n",
    "        return self\n",
    "    \n",
    "    #Ensemble Filter\n",
    "    def __ef_fit(self, X, y):\n",
    "        skf = StratifiedKFold(n_splits = self.n_splits, shuffle = True,\n",
    "                              random_state = self.random_state)\n",
    "        predictions = zeros((X.shape[0], 3))\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            \n",
    "            learning_algorithms = [DecisionTreeClassifier(), \\\n",
    "                                  KNeighborsClassifier(), \\\n",
    "                                  LogisticRegression()]\n",
    "            for index, model in enumerate(learning_algorithms):\n",
    "                model.fit(X_train, y_train)\n",
    "                predictions[test_idx, index] = model.predict(X_test)\n",
    "                \n",
    "        self.filter_ = self.__filtering_rule(predictions, y)\n",
    "        return self \n",
    "    \n",
    "    def __filter_resample(self, X, y):\n",
    "        return X[self.filter_], y[self.filter_]\n",
    "            \n",
    "    def __resample(self, X, y):\n",
    "        X = check_array(X)\n",
    "        \n",
    "        if (self.method == 'ENN') or (self.method == 'EF') or (self.method == 'IEKNCN') or (self.method == 'DROP') or (self.method == 'CMTNN') or (self.method == 'CVCF'):\n",
    "            return self.__filter_resample(X, y)\n",
    "        else:\n",
    "            raise ValueError('Undefined method')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        if self.method == 'ENN':\n",
    "            return self.__enn_fit(X, y)\n",
    "        elif self.method == 'EF':\n",
    "            return self.__ef_fit(X, y)\n",
    "        elif self.method == 'IEKNCN':\n",
    "            return self.__iekncn_fit(X, y)\n",
    "        elif self.method == 'DROP':\n",
    "            return self.__drop_fit(X, y)        \n",
    "        elif self.method == 'CMTNN':\n",
    "            return self.__cmtnn_fit(X, y)\n",
    "        elif self.method == 'CVCF':\n",
    "            return self.__cvcf_fit(X, y)\n",
    "        else:\n",
    "            raise ValueError('Undefined method')\n",
    "            \n",
    "    def fit_resample(self, X, y):\n",
    "        return self.fit(X, y).__resample(X, y)\n",
    "\n",
    "def classification(X,y,X_train,y_train,X_test,y_test,clf,method):\n",
    "    classifier = clf\n",
    "    y_score = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    pipe = Pipeline([('standardize', StandardScaler()),\n",
    "                  ('noise_handler', NoiseHandling(method = method, filter_type = 'consensus',n_neighbors = 5)),\n",
    "                  ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    score=pipe.score(X_test, y_test)\n",
    "    return score\n",
    "        \n",
    "def scores_rsfk(X,y,clf):\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5)\n",
    "    scores1,scores2,scores3,scores4,scores5=[],[],[],[],[]\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #Classifiers \"ENN\",\"EF\",\"IEKNCN\",\"DROP\",\"CVCF\"\n",
    "        scores1.append(classification(X,y,X_train,y_train,X_test,y_test,clf,\"ENN\"))\n",
    "        scores2.append(classification(X,y,X_train,y_train,X_test,y_test,clf,\"EF\"))\n",
    "        scores3.append(classification(X,y,X_train,y_train,X_test,y_test,clf,\"IEKNCN\"))\n",
    "        scores4.append(classification(X,y,X_train,y_train,X_test,y_test,clf,\"DROP\"))\n",
    "        scores5.append(classification(X,y,X_train,y_train,X_test,y_test,clf,\"CVCF\"))\n",
    "        \n",
    "    scores = np.array([scores1,scores2,scores3,scores4,scores5]).T\n",
    "    return scores\n",
    "\n",
    "def statistics(df,clf):\n",
    "    X = df.drop('Class', 1).to_numpy()\n",
    "    y = df['Class']\n",
    "    scores=scores_rsfk(X,y,clf)\n",
    "    return sp.posthoc_nemenyi_friedman(scores).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-654-e0014daa4eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df=Dfs5\n",
    "clf1 = DecisionTreeClassifier(random_state=42)\n",
    "clf2 = SVC(kernel='linear', probability=True,max_iter=1000)\n",
    "clf3 = KNeighborsClassifier(4)\n",
    "classifiers=[clf1,clf2,clf3]\n",
    "#table = pd.DataFrame([], columns=[\"ENN\", \"EF\",\"IEKNCN\",\"DROP\",\"CVCF\"])\n",
    "p_values=[]\n",
    "for i in range(3):    \n",
    "    for clf in classifiers:\n",
    "        p_values.append(statistics(df[i],clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86054911, 0.64926359, 0.7247668 , 0.86530605, 0.8653071 ],\n",
       "       [0.92      , 0.92      , 0.92      , 0.92      , 0.92      ],\n",
       "       [0.83621458, 0.88462739, 0.91673139, 0.88462739, 0.76220075],\n",
       "       [0.56313852, 0.49069361, 0.36490698, 0.56313852, 0.43491354],\n",
       "       [0.71867905, 0.36056213, 0.7196697 , 0.52200686, 0.7227285 ],\n",
       "       [0.76476467, 0.32344034, 0.68374919, 0.75023887, 0.75924862],\n",
       "       [0.29108424, 0.47088424, 0.53178246, 0.41877769, 0.50829345],\n",
       "       [0.75177364, 0.81618942, 0.8653065 , 0.87660124, 0.6592578 ],\n",
       "       [0.32849345, 0.4173753 , 0.40735192, 0.44301685, 0.44424855]])"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bckp=p_values\n",
    "np.shape(bckp)\n",
    "np.reshape(bckp,(9,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux5=[[0.86054911, 0.64926359, 0.7247668 , 0.86530605, 0.8653071 ],\n",
    "       [0.92      , 0.92      , 0.92      , 0.92      , 0.92      ],\n",
    "       [0.83621458, 0.88462739, 0.91673139, 0.88462739, 0.76220075],\n",
    "       [0.56313852, 0.49069361, 0.36490698, 0.56313852, 0.43491354],\n",
    "       [0.71867905, 0.36056213, 0.7196697 , 0.52200686, 0.7227285 ],\n",
    "       [0.76476467, 0.32344034, 0.68374919, 0.75023887, 0.75924862],\n",
    "       [0.29108424, 0.47088424, 0.53178246, 0.41877769, 0.50829345],\n",
    "       [0.75177364, 0.81618942, 0.8653065 , 0.87660124, 0.6592578 ],\n",
    "       [0.32849345, 0.4173753 , 0.40735192, 0.44301685, 0.44424855]]\n",
    "aux10=[[0.46522957, 0.58512103, 0.44482127, 0.57712187, 0.45422009],\n",
    "       [0.88462739, 0.92      , 0.84598617, 0.88462739, 0.91673139],\n",
    "       [0.78509994, 0.6082013 , 0.55683022, 0.81388171, 0.81715014],\n",
    "       [0.41183406, 0.48235078, 0.42295374, 0.49629718, 0.47961465],\n",
    "       [0.44161853, 0.82748416, 0.7764975 , 0.7951724 , 0.80246447],\n",
    "       [0.74081904, 0.62425312, 0.80585562, 0.52384395, 0.79782985],\n",
    "       [0.32218795, 0.42345201, 0.50675668, 0.38715632, 0.54403428],\n",
    "       [0.63802546, 0.61395303, 0.7840854 , 0.61838312, 0.50654095],\n",
    "       [0.32849345, 0.41469992, 0.41207372, 0.44277672, 0.43661123]]\n",
    "aux15 =[[0.27099899, 0.58305305, 0.58305305, 0.37122395, 0.61542595],\n",
    "       [0.5174993 , 0.7951724 , 0.82748416, 0.84449729, 0.81034544],\n",
    "       [0.32849345, 0.42129195, 0.4033066 , 0.44336541, 0.45255908],\n",
    "       [0.55576839, 0.69823867, 0.48557244, 0.59849724, 0.48557244],\n",
    "       [0.8653071 , 0.64926359, 0.86054911, 0.7247668 , 0.86530605],\n",
    "       [0.47268921, 0.49954643, 0.59905679, 0.55602896, 0.69850932],\n",
    "       [0.6091385 , 0.59301814, 0.46742738, 0.53782118, 0.36860383],\n",
    "       [0.76000691, 0.68424785, 0.75769925, 0.77676369, 0.8251765 ],\n",
    "       [0.53962729, 0.62908042, 0.63518592, 0.73484274, 0.71867905]]\n",
    "aux20 =[[0.22177857, 0.47614136, 0.67802682, 0.58674571, 0.67410683],\n",
    "       [0.40003733, 0.81715032, 0.78217939, 0.78217939, 0.72383428],\n",
    "       [0.32849345, 0.43781551, 0.38261274, 0.44529728, 0.46911889],\n",
    "       [0.56226718, 0.56288007, 0.38952732, 0.56571403, 0.38133396],\n",
    "       [0.83320214, 0.75130223, 0.73484274, 0.64967404, 0.74967306],\n",
    "       [0.75744321, 0.56562242, 0.69271208, 0.78340687, 0.76694668],\n",
    "       [0.66163253, 0.62867988, 0.6666049 , 0.7914325 , 0.49514001],\n",
    "       [0.92      , 0.92      , 0.92      , 0.92      , 0.92      ],\n",
    "       [0.41794778, 0.67891839, 0.64632382, 0.7628591 , 0.64632382]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrl}\n",
      "\\toprule\n",
      "{} &    ENN &     EF &  IEKNCN &   DROP &   CVCF & Database \\\\\n",
      "\\midrule\n",
      "Decision Tree &  0.271 &  0.583 &   0.583 &  0.371 &  0.615 &    Heart \\\\\n",
      "Decision Tree &  0.517 &  0.795 &   0.827 &  0.844 &  0.810 &    Heart \\\\\n",
      "Decision Tree &  0.328 &  0.421 &   0.403 &  0.443 &  0.453 &    Heart \\\\\n",
      "SVC           &  0.556 &  0.698 &   0.486 &  0.598 &  0.486 &     Pima \\\\\n",
      "SVC           &  0.865 &  0.649 &   0.861 &  0.725 &  0.865 &     Pima \\\\\n",
      "SVC           &  0.473 &  0.500 &   0.599 &  0.556 &  0.699 &     Pima \\\\\n",
      "KNC           &  0.609 &  0.593 &   0.467 &  0.538 &  0.369 &     Ring \\\\\n",
      "KNC           &  0.760 &  0.684 &   0.758 &  0.777 &  0.825 &     Ring \\\\\n",
      "KNC           &  0.540 &  0.629 &   0.635 &  0.735 &  0.719 &     Ring \\\\\n",
      "Promedio      &  0.547 &  0.617 &   0.624 &  0.621 &  0.649 &          \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "[2.28 2.61 2.78 3.56 3.78]\n"
     ]
    }
   ],
   "source": [
    "aux=aux15\n",
    "aux.append(np.reshape(aux,(9,5)).mean(axis=0))\n",
    "aux=np.around(aux,3)\n",
    "table = pd.DataFrame(aux, columns=[\"ENN\", \"EF\",\"IEKNCN\",\"DROP\",\"CVCF\"])\n",
    "table.index=[\"Decision Tree\",\"Decision Tree\",\"Decision Tree\",\"SVC\",\"SVC\",\"SVC\", \"KNC\",\"KNC\",\"KNC\",\"Promedio\"]\n",
    "table[\"Database\"]=[\"Heart\",\"Heart\",\"Heart\",\"Pima\",\"Pima\",\"Pima\",\"Ring\",\"Ring\",\"Ring\",\"\"]\n",
    "table\n",
    "print(table.to_latex())\n",
    "ranks=[]\n",
    "for i in range(9):    \n",
    "    ranks.append(list(ss.rankdata(aux[i])))\n",
    "print(np.around(np.array(ranks).mean(axis=0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
